{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard con Pytorch\n",
    "\n",
    "Tensorboard es una herramientas de visualización asociada al ecosistema de TensorFlow. Es tan popular, que también está soportada en Pytorch y su uso es habitual. Permite visualizar:\n",
    "\n",
    "- Métricas como la *loss* o la *accuracy*.\n",
    "- El grafo que representa la arquitectura del modelo\n",
    "- La evolución en tiempo real de los histogramas de pesos y *bias*\n",
    "- Información de rendmimiento computacional: uso de GPU, línea de tiempo de la ejecución, uso de memoria, etc...\n",
    "\n",
    "Vamos a ver un ejemplo en el que usamos una red convolucional sencilla para realizar una operación de clasificación sobre el conjunto de datos MNIST. En este conjunto de datos, tenemos que identificar en una imagen el tipo de prenda que muestran. Empezamos cargando el conjunto de datos utilizando el módulo torchvision.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, realizamos la definición de la red convolucional que vamos a entrenar y la instanciamos. La red está compuesta por los siguientes elementos:\n",
    "- Las imágenes de este data set tienen un único canal (b/n) y un tamaño de 28x28 píxeles.\n",
    "- Una capa Convolucional.\n",
    "- Una capa MaxPool2d.\n",
    "- y Tres capas lineales totalmente conectadas. Terminando en una salida compuest por 10 probabilidades, cada una asociada a un tipo de prenda.\n",
    "\n",
    "Luego, definimos la función de pérdida (*Cross-Entropy-Loss) y el optimizador (SGD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a empezar con la configuración de TensorBoard, creando un *SummaryWriter* que lleva asociada una ubicación en el sistema de ficheros, donde vamos a escribir los datos necesarias para luego utilizar TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tensorboard in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (2.15.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from tensorboard) (4.25.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from tensorboard) (3.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from tensorboard) (65.5.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from tensorboard) (3.5.2)\n",
      "Requirement already satisfied: six>1.9 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from tensorboard) (2.27.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from tensorboard) (2.31.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from tensorboard) (1.2.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from tensorboard) (1.26.4)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from tensorboard) (1.60.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (2024.2.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 07:40:36.880884: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-13 07:40:38.371310: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-13 07:40:38.371395: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-13 07:40:38.679486: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-13 07:40:39.298419: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-13 07:40:42.940357: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver, en primer lugar, cómo escribir una rejilla *grid* de imágenes aleatorias de nuestro conjunto de datos, para poder visualizarlas desde TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependiendo de cómo estemos usando este notebook, vamos a tener distintas formas de utilizar TensorBoard. Una que debería funciona en prácticamente cualquier entorno, es en un terminar ejecutar el siguiente comando.\n",
    "\n",
    "tensorboard --logdir=runs\n",
    "\n",
    "Otra cosa que podemos hacer con TensorBoard es visualizar la arquitectura del modelo. Para ello, debemos ejecutar el siguiente código\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images)\n",
    "writer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra herramienta de visualización que resulta muy útil son los *Projectors*. Estos generan una representación de baja dimensionalidad de datos de alta dimensionalidad. Para ello, utilizaremos el método *add_embedding*. Veamos un ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def select_n_random(data, labels, n=100):\n",
    "    '''\n",
    "    Selects n random datapoints and their corresponding labels from a dataset\n",
    "    '''\n",
    "    assert len(data) == len(labels)\n",
    "\n",
    "    perm = torch.randperm(len(data))\n",
    "    return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# select random images and their target indices\n",
    "images, labels = select_n_random(trainset.data, trainset.targets)\n",
    "\n",
    "# get the class labels for each image\n",
    "class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# log embeddings\n",
    "features = images.view(-1, 28 * 28)\n",
    "writer.add_embedding(features,\n",
    "                    metadata=class_labels,\n",
    "                    label_img=images.unsqueeze(1))\n",
    "writer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En TensorBoard, deberíamos tener una pestaña más que contiene la información generada por el Proyector.\n",
    "\n",
    "A continuación, vamos a ver otro ejemplo, en este caso de cómo generar información sobre la evolución de la función de pérdida (*loss*), y además de una vista de las predicciones que está generando el modelo *plot_classes_pred*. Para ello, tenemos que definir un par de funciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer uso de la función anterior, *plot_classes_pred* tenemos que utilizarla en el contexto de un bucle de entrenamiento. Veamos cómo se integra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m outputs \u001b[38;5;241m=\u001b[39m net(inputs)\n\u001b[1;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     18\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si abrimos Tensorboard, y recargamos, veremos una nueva pestaña *Scalars* donde podemos visualizar la evolución del valor de la función de pérdida con el tiempo.\n",
    "\n",
    "En la pestaña *Images*, después de recargar su contenido, veremos una versión de la imagen que muestra ejemplos aleatorios del conjunto de entrenamiento, con las etiquetas predichas, la probabilidad asociada y las etiquetas esperadas.\n",
    "\n",
    "\n",
    "Una última cosa que vamos a hacer es generar *PrecisionRecallCurves* para evaluar la precisión de nuestro clasificador. \n",
    "Esta métrica muestra el balance entre dos métricas para un clasificador:\n",
    "\n",
    "- *Precision*: Indica la precisión del modelo y se calcula como *true positives*/*true positives*+*false positives*\n",
    "- *Recall*: Indica el grado de completitud y se calcula como *true positives*/*true positives*+*false negatives*\n",
    "\n",
    "Como siempre, primero, ejecutamos el código Python que genera dicha información. Luego, iremos a Tensorboard a ver los resultados en una pestaña nueva que se generará llamada *PR Curves*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. gets the probability predictions in a test_size x num_classes Tensor\n",
    "# 2. gets the preds in a test_size Tensor\n",
    "# takes ~10 seconds to run\n",
    "class_probs = []\n",
    "class_label = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_label.append(labels)\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_label = torch.cat(class_label)\n",
    "\n",
    "# helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_label, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    '''\n",
    "    tensorboard_truth = test_label == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_truth,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "    writer.close()\n",
    "\n",
    "# plot all the pr curves\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio\n",
    "\n",
    "Utilizando como el base, el código resultante del ejercicio al final del notebook *optimizers.ipynb*, haz los cambios pertinentes para registrar la figura de la comparativa de la loss_function entre los 3 optimizadores. Comprueba luego que puedes visualizarla. La solución a este ejercicio es proporcionada de forma directa para su visualización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchmetrics import HammingDistance, F1Score, MetricCollection\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/cifar10_experiment_1')\n",
    "\n",
    "# Inicializamos el modelo, la métrica y el optimizador\n",
    "metrics = MetricCollection([HammingDistance(task='multiclass', num_classes=10), F1Score(task='multiclass',num_classes=10, threshold=0.5)])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# Define the network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Define the loss function\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the training function\n",
    "def train(net, trainloader, optimizer, num_epochs=2):\n",
    "    loss_values = []\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # save losses to plot later\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                loss_values.append(running_loss / 2000)\n",
    "                running_loss = 0.0\n",
    "                metrics(torch.argmax(outputs,dim=1), labels)\n",
    "                 # ...log the running loss\n",
    "                writer.add_scalar('training loss',\n",
    "                            running_loss / 2000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss / len(trainloader)}\")\n",
    "        print(f\"Epoch {epoch+1}, Metrics: {metrics.compute()}\")\n",
    "        # Reinicializamos la métrica para la siguiente época\n",
    "        metrics.reset()\n",
    "\n",
    "    return loss_values\n",
    "\n",
    "# SGDs\n",
    "net_SGD = Net()\n",
    "optimizer_SGD = optim.SGD(net_SGD.parameters(), lr=0.001, momentum=0.9)\n",
    "loss_SGD = train(net_SGD, trainloader, optimizer_SGD)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypython",
   "language": "python",
   "name": "mypython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
