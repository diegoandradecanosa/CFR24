{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Técnicas de Score de modelos en Python\n",
    "\n",
    "Las técnicas de Score (o puntuación) de modelos de ML evalúan su precisión. Habitualmente se basan en realizar algún tipo de comparación entre la salida obtenida y la salida deseada.\n",
    "\n",
    "Hay muchas técnicas de Score en ML, pero una familia de técnicas muy populares son las basadas en las Confusion matrices. Estas matrices cruzan las predicciones posibles, con las salidas deseadas, estableciendo una clasificación de la salida del modelo como:\n",
    "- TN: True Negative, el modelo predice correctamente un resultado negativo.\n",
    "- FN: False Negative, el modelo predice incorrectamente un resultado negativo.\n",
    "- TP: True Positive, el modelo predice correctamente un resultado positivo.\n",
    "- FP: False Positive, el modelo predice incorrectamente un resultado positivo.\n",
    "\n",
    "Las técnicas más comunes populares de este tipo son: precision, recall, f1-score y accuracy.\n",
    "\n",
    "En Pytorch no se implementa nativamente ninguna técnica de Score. Pero, en el ecosistema de Pytorch, hay un librería estándar de-facto que se puede usar para ello: *torchmetrics*\n",
    "\n",
    "Este librería tiene un API que implementa varias métricas con una interfaz común que proporciona los métodos: *update()*, *compute()* y *reset()*. Veamos un ejemplo completo de su uso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-1.3.1-py3-none-any.whl (840 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.4/840.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>17.1 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from torchmetrics) (23.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from torchmetrics) (2.2.0)\n",
      "Collecting lightning-utilities>=0.8.0\n",
      "  Downloading lightning_utilities-0.10.1-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: numpy>1.20.0 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from torchmetrics) (1.26.4)\n",
      "Requirement already satisfied: setuptools in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (65.5.0)\n",
      "Requirement already satisfied: typing-extensions in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: networkx in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.2.1)\n",
      "Requirement already satisfied: triton==2.2.0 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (2.2.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (12.1.3.1)\n",
      "Requirement already satisfied: jinja2 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (2.19.3)\n",
      "Requirement already satisfied: filelock in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.13.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (11.4.5.107)\n",
      "Requirement already satisfied: fsspec in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (2024.2.0)\n",
      "Requirement already satisfied: sympy in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics) (12.2.140)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /mnt/netapp2/Store_uni/home/ulc/es/dac/mypython/lib/python3.10/site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
      "Installing collected packages: lightning-utilities, torchmetrics\n",
      "Successfully installed lightning-utilities-0.10.1 torchmetrics-1.3.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.7850720107555389\n",
      "Epoch 1, F1-Score: 0.4954128563404083\n",
      "Epoch 2, Loss: 0.7814775586128235\n",
      "Epoch 2, F1-Score: 0.5023255944252014\n",
      "Epoch 3, Loss: 0.778220784664154\n",
      "Epoch 3, F1-Score: 0.5046728849411011\n",
      "Epoch 4, Loss: 0.7750377476215362\n",
      "Epoch 4, F1-Score: 0.5058547854423523\n",
      "Epoch 5, Loss: 0.7719135165214539\n",
      "Epoch 5, F1-Score: 0.5075187683105469\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchmetrics import F1Score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Definimos un modelo muy simple para clasificación binaria\n",
    "class BinaryClassificationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryClassificationModel, self).__init__()\n",
    "        self.linear = nn.Linear(10, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = torch.sigmoid(self.linear(x))\n",
    "        return output\n",
    "\n",
    "# Inicializamos el modelo, la métrica y el optimizador\n",
    "model = BinaryClassificationModel()\n",
    "metric = F1Score(task='binary',num_classes=1, threshold=0.5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Creamos un dataset de ejemplo aleatorio\n",
    "inputs = torch.randn(100, 10)\n",
    "targets = torch.randint(0, 2, (100,)).float()  # Binary targets\n",
    "dataset = TensorDataset(inputs, targets)\n",
    "dataloader = DataLoader(dataset, batch_size=10)\n",
    "\n",
    "# Bucle de entrenamiento\n",
    "for epoch in range(5):  # 5 épocas\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = nn.BCELoss()(outputs.view(-1), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        # Actualizamos la métrica\n",
    "        metric(outputs.view(-1), labels)\n",
    "        \n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(dataloader)}\")\n",
    "    print(f\"Epoch {epoch+1}, F1-Score: {metric.compute()}\")\n",
    "\n",
    "# Reinicializamos la métrica para la siguiente época\n",
    "metric.reset()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos usar una estructura de tipo *MetricCollection* para recopilar dos métricas a la vez. Veamos una adaptación del ejemplo anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.799572902917862\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 37\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# Llamamos a la colección de métricas\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# ESCRIBE TU CÓDIGO AQUÍ\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# metric(...)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Metrics: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mmetrics\u001b[49m\u001b[38;5;241m.\u001b[39mcompute()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Reinicializamos la métrica para la siguiente época\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# ESCRIBE TU CÓDIGO AQUÍ\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# metric. ... \u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "from torchmetrics import HammingDistance, F1Score, MetricCollection\n",
    "\n",
    "\n",
    "# Inicializamos el modelo, la métrica y el optimizador\n",
    "model = BinaryClassificationModel()\n",
    "# Creamos una colección de métricas\n",
    "# ESCRIBE TU CÓDIGO AQUÍ\n",
    "# metric = ...\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Creamos un dataset de ejemplo aleatorio\n",
    "inputs = torch.randn(100, 10)\n",
    "targets = torch.randint(0, 2, (100,)).long()  # Binary targets\n",
    "dataset = TensorDataset(inputs, targets)\n",
    "dataloader = DataLoader(dataset, batch_size=10)\n",
    "\n",
    "# Bucle de entrenamiento\n",
    "for epoch in range(5):  # 5 épocas\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = nn.BCELoss()(outputs.view(-1), labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        # Actualizamos la métrica\n",
    "        pred_labels = torch.round(outputs.view(-1))\n",
    "        # Llamamos a la colección de métricas\n",
    "        # ESCRIBE TU CÓDIGO AQUÍ\n",
    "        # metric(...)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(dataloader)}\")\n",
    "    print(f\"Epoch {epoch+1}, Metrics: {metrics.compute()}\")\n",
    "    # Reinicializamos la métrica para la siguiente época\n",
    "    # ESCRIBE TU CÓDIGO AQUÍ\n",
    "    # metric. ... "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio\n",
    "\n",
    "Utilizando como el base, el código resultante del ejercicio al final del notebook *optimizers.ipynb*, haz los cambios pertinentes para calcular la Hamming Distance y el BinaryF1Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchmetrics import HammingDistance, F1Score, MetricCollection\n",
    "\n",
    "\n",
    "# Inicializamos el modelo, la métrica y el optimizador\n",
    "metrics = MetricCollection([HammingDistance(task='multiclass', num_classes=10), F1Score(task='multiclass',num_classes=10, threshold=0.5)])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "# Define the network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Define the loss function\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the training function\n",
    "def train(net, trainloader, optimizer, num_epochs=2):\n",
    "    loss_values = []\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # save losses to plot later\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                loss_values.append(running_loss / 2000)\n",
    "                running_loss = 0.0\n",
    "                metrics(torch.argmax(outputs,dim=1), labels)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss / len(dataloader)}\")\n",
    "        print(f\"Epoch {epoch+1}, Metrics: {metrics.compute()}\")\n",
    "        # Reinicializamos la métrica para la siguiente época\n",
    "        metrics.reset()\n",
    "\n",
    "    return loss_values\n",
    "\n",
    "# SGD\n",
    "net_SGD = Net()\n",
    "optimizer_SGD = optim.SGD(net_SGD.parameters(), lr=0.001, momentum=0.9)\n",
    "loss_SGD = train(net_SGD, trainloader, optimizer_SGD)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mypython",
   "language": "python",
   "name": "mypython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
